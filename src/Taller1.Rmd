---
title: "MMACC- Análisis Avanzado de Datos:  Taller1"
author: Raúl Andrés Rodriguez - Richard Felipe Bolaños
output: html_document
date: "2024-02-27"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r paquetes_configuracion,include=FALSE, echo=FALSE}

library(pacman)

p_load(tidyverse,kableExtra,glmnet,data.table,car,pracma)

taller1<-fread("taller1.txt",sep="auto")


```

## Problema

El conjunto de datos taller1.txt contiene la información del perfíl
genómico de un conjunto de 1200 líneas celulares. Para estas se busca
determinar cuáles de los 5000 genes (ubicados en cada columna) son de
relevancia para la predicción de la variable respuesta (efectividad del
tratamiento anticancer, medida como variable continua).

## Dataset

```{r, echo=FALSE, warning=FALSE}

head(taller1) %>% data.frame() %>% select(y,V1,V2,V3,V4,V5,V4995,V4996,V4997,V4998,V4999,V5000) %>% 
knitr::kable(booktabs = FALSE,align="c") %>%
kable_styling(position = "center")


```

## Pregunta \# 1

¿Hay multicolinealidad en los datos? Explique sucintamente

Dado que la matriz de diseño es de dimensión $n\leq p$ usar tecnicas
como el VIF no es posible y calcular las correlaciones entre las
covariables no es necesariamente un sintoma de multicolinealidad, por lo
que la existencia de esta misma puede ocurrir por la relación implicita
que existe por la naturaleza de las variables. Sin embargo como uno de
los principios de la existencia multicolinealidad es que las variables
regresoras no sean ortogonales, es posible que exista al menos una
variable regresora que es producto de una combinación lineal de otras
variables regresoras, en ese sentido la existencia de la
multicolinealidad es latente en el conjunto de datos.

## Pregunta \# 2

Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en
dos partes: Entrenamiento: 1000 líneas celulares Prueba: 200 líneas
celulares.

```{r}
# Establecer la semilla para reproducibilidad
set.seed(123)

# Crear un vector de índices de filas
indices <- 1:1200

# Seleccionar aleatoriamente 1000 índices para el primer conjunto
indices_1000 <- sample(indices, 1000)

# Crear el primer conjunto de datos con 1000 filas
taller1_1000 <- taller1[indices_1000, ]

# Remover los índices seleccionados para el primer conjunto
indices <- setdiff(indices, indices_1000)

# Los índices restantes serán utilizados para el segundo conjunto de datos
taller1_200 <- taller1[indices, ]
```

## Pregunta \# 3

Usando los 1000 datos de entrenamiento, determine los valores de
$\lambda_R$ y $\lambda_L$ de regesión ridge y lasso, respectivamente,
que minimicen el error cuadrático medio (ECM) mediante validación
externa. Utilice el método de validación externa que considere más
apropiado

Usando la validación cruzada en fold como validación externa, se
evaluaran 20 lambdas espaciados en escala logaritmica en 10 folds y
encontrar el mejor lambda para la regresión *Ridge* y *Lasso*.

```{r message=FALSE, warning=FALSE}

lambda<-logseq(0.05, 1, 25)


## RIDGE

ridge_models <- cv.glmnet(as.matrix(taller1_1000[, -1]), taller1_1000$y,
                          alpha=0, 
                          lambda=lambda,
                          nfolds=10)

## LASSO
lasso_models <- cv.glmnet(as.matrix(taller1_1000[, -1]), taller1_1000$y,
                          alpha=1, 
                          lambda=lambda,
                          nfolds=10)
```

```{r echo=FALSE, warning=FALSE}

data.frame(Lambdas= c("Min","1se"),
           Ridge=c(ridge_models$lambda.min,ridge_models$lambda.1se),
           Lasso=c(lasso_models$lambda.min,lasso_models$lambda.1se)) %>% 
  knitr::kable(booktabs = FALSE,align="c") %>% kable_styling(position = "center")


```

## Pregunta \# 4

Ajuste la regresión ridge y lasso con los valores estimados de λr y λl
obtenidos en (3) usando los 1000 datos de entrenamiento.

```{r message=FALSE, warning=FALSE}

#RIDGE
ridge_model_min <- glmnet(as.matrix(taller1_1000[, -1]), taller1_1000$y, alpha=0, lambda=ridge_models$lambda.min)

ridge_model_1se <- glmnet(as.matrix(taller1_1000[, -1]), taller1_1000$y, alpha=0, lambda=ridge_models$lambda.1se)


#LASSO
lasso_model_min <- glmnet(as.matrix(taller1_1000[, -1]), taller1_1000$y, alpha=1, lambda=lasso_models$lambda.min)

lasso_model_1se <- glmnet(as.matrix(taller1_1000[, -1]), taller1_1000$y, alpha=1, lambda=lasso_models$lambda1se)
```

## Pregunta \# 5

Para los modelos ajustados en (4) determine el más apropiado para
propósitos de predicción. Considere únicamente el ECM en los 200 datos
de prueba para su decisión.

```{r message=FALSE, warning=FALSE}}

#No. 1 
# Realizar predicciones en los datos de prueba
predicciones_rmin <- predict(ridge_model_min, as.matrix(taller1_200[, -1]))

# Calcular el error cuadrático medio
ecm_ridge_min <- mean((predicciones_rmin - taller1_200$y)^2)

#No. 2 
# Realizar predicciones en los datos de prueba
predicciones_rse1 <- predict(ridge_model_1se, as.matrix(taller1_200[, -1]))

# Calcular el error cuadrático medio
ecm_ridge_1se <- mean((predicciones_rse1 - taller1_200$y)^2)

#No. 3 
# Realizar predicciones en los datos de prueba
predicciones_lmin <- predict(lasso_model_min, as.matrix(taller1_200[, -1]))

# Calcular el error cuadrático medio
ecm_lasso_min <- mean((predicciones_lmin - taller1_200$y)^2)

#No. 4 
# Realizar predicciones en los datos de prueba
predicciones_lse1 <- predict(lasso_model_1se, as.matrix(taller1_200[, -1]))

# Calcular el error cuadrático medio
ecm_lasso_1se <- mean((predicciones_lse1 - taller1_200$y)^2)



data.frame(Modelos=rep(c("Ridge","Lasso"),each= 2),Lambdas=c("Min","Se1"),
           Value=c(ridge_models$lambda.min,ridge_models$lambda.1se,
                   lasso_models$lambda.min,lasso_models$lambda.1se),
           ECM= c(ecm_ridge_min, ecm_ridge_1se,ecm_lasso_min, ecm_lasso_1se)) %>% 
  knitr::kable(booktabs = FALSE,align="c") %>% kable_styling(position = "center")
  






```

## Pregunta \# 6

Ajuste el modelo seleccionado en (5) para los 1200 datos. Note que en
este punto ya tiene un λ estimado y un modelo seleccionado.

## Pregunta \# 7

Grafique las trazas de los coeficientes en función de la penalización
para el modelo ajustado en 6

## Pregunta \# 8

En un párrafo resuma los resultados obtenidos dado el objetivo inicial
del estudio.
