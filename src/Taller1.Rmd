---
title: "Taller1"
output: html_document
date: "2024-02-27"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r paquetes_configuracion,include=FALSE, echo=FALSE}

library(pacman)

p_load(tidyverse,kableExtra,glmnet,data.table,car)

datos<-fread("taller1.txt",sep="auto")


```

## Problema

El conjunto de datos taller1.txt contiene la información del perfíl
genómico de un conjunto de 1200 líneas celulares. Para estas se busca
determinar cuáles de los 5000 genes (ubicados en cada columna) son de
relevancia para la predicción de la variable respuesta (efectividad del
tratamiento anticancer, medida como variable continua).

## Dataset

```{r, echo=FALSE, warning=FALSE}

head(datos) %>% data.frame() %>% select(y,V1,V2,V3,V4,V5,V4995,V4996,V4997,V4998,V4999,V5000) %>% 
knitr::kable(booktabs = FALSE,align="c") %>%
kable_styling(position = "center")





```

## Pregunta \# 1

¿Hay multicolinealidad en los datos? Explique sucintamente

Dado que la matriz de diseño es de dimensión $n\leq p$, puede existir al
menos una variable regresora que es producto de una combinación lineal
de otras variables regresoras.

## Pregunta \# 2

Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en
dos partes: Entrenamiento: 1000 líneas celulares Prueba: 200 líneas
celulares.

```{r}
# Establecer la semilla para reproducibilidad
set.seed(123)

# Crear un vector de índices de filas
indices <- 1:1200

# Seleccionar aleatoriamente 1000 índices para el primer conjunto
indices_1000 <- sample(indices, 1000)

# Crear el primer conjunto de datos con 1000 filas
taller1_1000 <- taller1[indices_1000, ]

# Remover los índices seleccionados para el primer conjunto
indices <- setdiff(indices, indices_1000)

# Los índices restantes serán utilizados para el segundo conjunto de datos
taller1_200 <- taller1[indices, ]
```

## Pregunta \# 3

Usando los 1000 datos de entrenamiento, determine los valores de λr y λl
de regesión ridge y lasso, respectivamente, que minimicen el error
cuadrático medio (ECM) mediante validación externa. Utilice el método de
validación externa que considere más apropiado

### Regresión Rigde

```{r}
# Crear matrix con valores lambda
log_lambda <- seq(6, -2, length=100) # In reverse
lambda_matrix <- 10^log_lambda

# Create 100 ridge models
ridge_models <- glmnet(as.matrix(taller1_1000[, -1]), taller1_1000$y, alpha=0, lambda=lambda_matrix)

# Get coefficients of all 100 models
ridge_coef <- coef(ridge_models)

# Display coefficients for 6 models.
# Ridge Models are displayed in decreasing order of lambda.
round(ridge_coef[, c(1:3, 98:100)], 6)
```

```{r}
# Find SSE
SSE_train <- colSums((train_pred_ridge - taller1_1000$y)^2)
SSE_valid <- colSums((valid_pred_ridge - taller1_200$y)^2)

SST_train <- SSE_train + colSums((train_pred_ridge - mean(taller1_1000$y))^2)
SST_valid <- SSE_valid + colSums((valid_pred_ridge - mean(taller1_200$y))^2)


# Find r-Squared
r2_train_list <- 1 - SSE_train / SST_train
r2_valid_list <- 1 - SSE_valid / SST_valid

round(r2_valid_list[c(1:3, 98:100)],4)
```

```{r}
plot(log_lambda, r2_train_list, ylim=c(-0.2,1), pch=".", col="salmon", 
     xlab="ln(lambda)", ylab="r-Squared", main="Training and Validation Scores (Ridge)")

lines(log_lambda, r2_train_list, col="salmon", lwd=2)

lines(log_lambda, r2_valid_list, col="cornflowerblue", lwd=2)

legend(75, 1, legend=c("Training Acc", "Validation Acc"),
       col=c("salmon", "cornflowerblue"), lty=1, lwd=2, cex=0.8)
```

```{r}
best_valid_r2 <- max(r2_valid_list)
best_valid_r2_ix <- which.max(r2_valid_list)
best_log_lambda <- log_lambda[best_valid_r2_ix]

cat('Index of Optimal r-Squared:    ', best_valid_r2_ix, '\n',
    'Value of Optimal r-Squared:    ', best_valid_r2, '\n',
    'Value of Optimal log(lambda):  ', best_log_lambda, sep='')
```

### Regresión Lasso

```{r}
# Create 100 LASSO models
lasso_models <- glmnet(taller1_1000[, -1], taller1_1000$y, alpha=1, lambda=lambda_matrix)

# Get coefficients of all 100 models
lasso_coef <- coef(lasso_models)

# Display coefficients for 6 models. 
# LASSO Models are displayed in decreasing order of lambda.
round(lasso_coef[, c(1:3, 98:100)], 6)
```

```{r}
train_pred_lasso <- predict(lasso_models, as.matrix(taller1_1000[, -1]))
valid_pred_lasso <- predict(lasso_models, as.matrix(taller1_200[, -1]))

valid_pred_lasso[,c(1,2,99,100)]
```

```{r}
# Find SSE
SSE_train <- colSums((train_pred_lasso - taller1_1000$y)^2)
SSE_valid <- colSums((valid_pred_lasso - taller1_200$y)^2)


SST_train <- SSE_train + colSums((train_pred_ridge - mean(taller1_1000$y))^2)
SST_valid <- SSE_valid + colSums((valid_pred_ridge - mean(taller1_200$y))^2)

# Find r-Squared
r2_train_list <- 1 - SSE_train / SST_train
r2_valid_list <- 1 - SSE_valid / SST_valid

round(r2_valid_list[c(1:3, 98:100)],4)
```

```{r}
best_valid_r2 <- max(r2_valid_list)
best_valid_r2_ix <- which.max(r2_valid_list)
best_log_lambda <- log_lambda[best_valid_r2_ix]

cat('Index of Optimal r-Squared:    ', best_valid_r2_ix, '\n',
    'Value of Optimal r-Squared:    ', best_valid_r2, '\n',
    'Value of Optimal log(lambda):  ', best_log_lambda, sep='')
```

## Pregunta \# 4

Ajuste la regresi´on ridge y lasso con los valores estimados de λr y λl
obtenidos en (3) usando los 1000 datos de entrenamiento.

## Pregunta \# 5

Para los modelos ajustados en (4) determine el m´as apropiado para
prop´ositos de predicci´on. Considere ´unicamente el ECM en los 200
datos de prueba para su decisi´on.

## Pregunta \# 6

Ajuste el modelo seleccionado en (5) para los 1200 datos. Note que en
este punto ya tiene un λ estimado y un modelo seleccionado.

## Pregunta \# 7

Grafique las trazas de los coeficientes en funci´on de la penalizaci´on
para el modelo ajustado en8

## Pregunta \# 8

En un p´arrafo resuma los resultados obtenidos dado el objetivo inicial
del estudio.
